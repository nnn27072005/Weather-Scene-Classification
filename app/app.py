import streamlit as st
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import numpy as np
import joblib
# ==========================================
# PH·∫¶N 1: ƒê·ªäNH NGHƒ®A MODEL (B·∫ÆT BU·ªòC)
# ==========================================
# B·∫°n H√ÉY COPY PASTE to√†n b·ªô Class ResNet, DenseNet, 
# ResidualBlock, DenseBlock v√†o ƒë√¢y ƒë·ªÉ torch.load kh√¥ng b·ªã l·ªói.

# V√≠ d·ª• (Ch·ªâ l√† placeholder, b·∫°n thay b·∫±ng code th·∫≠t c·ªßa b·∫°n):
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride = 1):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1)
        self.batch_norm1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1)
        self.batch_norm2 = nn.BatchNorm2d(out_channels)
        self.downsample = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.downsample = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = stride), nn.BatchNorm2d(out_channels))
        self.relu = nn.ReLU()
    def forward(self, x):
        shortcut = x.clone()
        x = self.conv1(x)
        x = self.batch_norm1(x)
        x = self.relu(x)
        x = self.conv2(x)
        x = self.batch_norm2(x)
        x += self.downsample(shortcut)
        x = self.relu(x)
        return x
            

class ResNet(nn.Module):
    def __init__(self, residual_block, n_blocks_lst, n_classes):
        super(ResNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64 , kernel_size = 7, stride = 2, padding=3)
        self.batch_norm1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.conv2 = self.create_layer(residual_block, 64, 64, n_blocks_lst[0], 1)
        self.conv3 = self.create_layer(residual_block, 64, 128, n_blocks_lst[1], 2)
        self.conv4 = self.create_layer(residual_block, 128, 256, n_blocks_lst[2], 2)
        self.conv5 = self.create_layer(residual_block, 256, 512, n_blocks_lst[3], 2)
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(512, n_classes)
    def create_layer(self, residual_block, in_channels, out_channels, n_blocks, stride):
        blocks = []
        first_block = residual_block(in_channels, out_channels, stride)
        blocks.append(first_block)
        for idx in range(1, n_blocks):
            block = residual_block(out_channels, out_channels, stride = 1)
            blocks.append(block)
        block_sequential = nn.Sequential(*blocks)

        return block_sequential

    def forward(self, x):
        x = self.conv1(x)
        x = self.batch_norm1(x)
        x = self.maxpool(x)
        x = self.relu(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = self.avgpool(x)
        x = self.flatten(x)
        x = self.fc1(x)
        return x

class BottleneckBlock(nn.Module):
    def __init__(self, in_channels, growth_rate):
        super(BottleneckBlock,self).__init__()
        self.bn1 = nn.BatchNorm2d(in_channels)
        self.conv1 = nn.Conv2d(in_channels, 4*growth_rate,
                               kernel_size =1, bias = False)
        self.bn2 = nn.BatchNorm2d(4*growth_rate)
        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate,
                              kernel_size=3, padding=1, bias=False)
        self.relu = nn.ReLU()

    def forward(self, x):
        res = x
        x = self.bn1(x)
        x = self.relu(x)
        x = self.conv1(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.conv2(x)
        x = torch.cat([res,x], 1)
        return x

class DenseBlock(nn.Module):
    def __init__(self, num_layers, in_channels, growth_rate):
        super(DenseBlock,self).__init__()
        layers = []
        for i in range(num_layers):
            layers.append(BottleneckBlock(in_channels + i*growth_rate
                         , growth_rate))
        self.block = nn.Sequential(*layers)

    def forward(self, x):
        return self.block(x)

class DenseNet(nn.Module):
    def __init__(self, num_blocks, growth_rate, num_classes):
        super(DenseNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 2*growth_rate, kernel_size=7, 
                              padding=3, stride=2, bias=False)
        self.bn1 = nn.BatchNorm2d(2*growth_rate)
        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.dense_blocks = nn.ModuleList()
        in_channels = 2*growth_rate
        
        for i, num_layers in enumerate(num_blocks):
            self.dense_blocks.append(DenseBlock(
                num_layers, in_channels, growth_rate
            ))
            in_channels += num_layers * growth_rate
            if i != len(num_blocks) -1:
                out_channels = in_channels // 2
                self.dense_blocks.append(nn.Sequential(
                    nn.BatchNorm2d(in_channels),
                    # Th√™m ReLU inplace v√†o transition layer ƒë·ªÉ ti·∫øt ki·ªám RAM
                    nn.ReLU(inplace=True), 
                    nn.Conv2d(in_channels, out_channels, 
                    kernel_size=1, bias=False),
                    nn.AvgPool2d(kernel_size=2, stride=2) # Transition th∆∞·ªùng c√≥ pooling
                ))
                in_channels = out_channels

        self.bn2 = nn.BatchNorm2d(in_channels)
        
        # --- S·ª¨A L·ªñI SHAPE T·∫†I ƒê√ÇY ---
        # Thay v√¨ AvgPool2d(7), d√πng AdaptiveAvgPool2d((1, 1))
        # N√≥ √©p m·ªçi k√≠ch th∆∞·ªõc ·∫£nh v·ªÅ 1x1 -> Flatten s·∫Ω lu√¥n kh·ªõp v·ªõi self.fc
        self.pool2 = nn.AdaptiveAvgPool2d((1, 1)) 
        
        # --- S·ª¨A L·ªñI MEMORY T·∫†I ƒê√ÇY ---
        # Th√™m inplace=True ƒë·ªÉ ti·∫øt ki·ªám b·ªô nh·ªõ GPU
        self.relu = nn.ReLU(inplace=True) 
        
        self.fc = nn.Linear(in_channels, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.pool1(x)
        
        for block in self.dense_blocks:
            x = block(x)
            
        x = self.bn2(x)
        x = self.relu(x)
        
        # Sau b∆∞·ªõc n√†y, x s·∫Ω c√≥ d·∫°ng (Batch, Channel, 1, 1)
        x = self.pool2(x) 
        
        # Flatten: (Batch, Channel, 1, 1) -> (Batch, Channel)
        x = torch.flatten(x, 1) 
        
        # L√∫c n√†y Channel kh·ªõp v·ªõi in_channels c·ªßa self.fc -> H·∫øt l·ªói
        x = self.fc(x)
        return x

# ==========================================
# PH·∫¶N 2: C·∫§U H√åNH V√Ä LOAD MODEL
# ==========================================

# ƒê·ªãnh nghƒ©a c√°c nh√£n (Labels) - B·∫°n h√£y s·ª≠a l·∫°i cho ƒë√∫ng v·ªõi dataset c·ªßa b·∫°n
WEATHER_CLASSES = ['dew', 'fogsmog', 'frost', 'glaze', 'hail', 'lightning', 'rain', 'rainbow', 'rime', 'sandstorm', 'snow']
SCENE_CLASSES = ['Buildings', 'Forest', 'Glacier', 'Mountain', 'Sea', 'Street']

def transform(img, img_size=(224, 224)):
    img = img.resize(img_size)
    img = np.array(img)[..., :3] # L·∫•y 3 k√™nh m√†u (b·ªè k√™nh trong su·ªët n·∫øu c√≥)
    img = torch.tensor(img).permute(2,0,1).float() # Chuy·ªÉn sang (C, H, W)
    normalized_img = img / 255.0 # Chu·∫©n h√≥a v·ªÅ 0-1
    return normalized_img

# H√†m load model (D√πng cache ƒë·ªÉ kh√¥ng ph·∫£i load l·∫°i m·ªói l·∫ßn click)
@st.cache_resource
def load_models():
    device = torch.device('cpu') # Deploy web th∆∞·ªùng ch·∫°y CPU cho r·∫ª/ti·ªán
    path_weather = '../models/model_weather.pth'
    path_scenes = '../models/model_scenes.pth'
    # Load Model Weather
    try:
        model_weather = joblib.load(path_weather)
        model_weather.eval()
    except Exception as e:
        model_weather = None
        print(f"L·ªói load Weather: {e}")

    # Load Model Scenes
    try:
        model_scenes = joblib.load(path_scenes)
        model_scenes.eval()
    except Exception as e:
        model_scenes = None
        print(f"L·ªói load Scenes: {e}")
        
    return model_weather, model_scenes

model_weather, model_scenes = load_models()

# ==========================================
# PH·∫¶N 3: GIAO DI·ªÜN STREAMLIT
# ==========================================

st.title("üì∏ AI Image Classifier Hub")
st.sidebar.title("Ch·ªçn ch·ª©c nƒÉng")

# T·∫°o Menu b√™n tr√°i
app_mode = st.sidebar.selectbox("Ch·ªçn lo·∫°i Model:",
                                ["D·ª± ƒëo√°n Th·ªùi ti·∫øt (Weather)", "Ph√¢n lo·∫°i Khung c·∫£nh (Scenes)"])

if app_mode == "D·ª± ƒëo√°n Th·ªùi ti·∫øt (Weather)":
    st.header("üå§Ô∏è Weather Classification")
    model = model_weather
    classes = WEATHER_CLASSES
    
elif app_mode == "Ph√¢n lo·∫°i Khung c·∫£nh (Scenes)":
    st.header("üèûÔ∏è Scene Classification")
    model = model_scenes
    classes = SCENE_CLASSES

# Khu v·ª±c upload ·∫£nh
uploaded_file = st.file_uploader("Ch·ªçn m·ªôt b·ª©c ·∫£nh...", type=["jpg", "png", "jpeg"], key=app_mode)

if uploaded_file is not None:
    # Hi·ªÉn th·ªã ·∫£nh
    image = Image.open(uploaded_file).convert('RGB')
    st.image(image, caption='·∫¢nh ƒë√£ t·∫£i l√™n', width=400)
    
    if st.button('D·ª± ƒëo√°n ngay'):
        if model is None:
            st.error("Ch∆∞a t√¨m th·∫•y file model!")
        else:
            with st.spinner('ƒêang ph√¢n t√≠ch...'):
                try:
                    # 1. G·ªçi h√†m transform th·ªß c√¥ng c·ªßa b·∫°n
                    # L∆∞u √Ω: S·ª≠a (224, 224) th√†nh k√≠ch th∆∞·ªõc th·∫≠t b·∫°n ƒë√£ train (v√≠ d·ª• (150, 150)?)
                    img_tensor = transform(image, img_size=(224, 224)) 
                    
                    # 2. Quan tr·ªçng: Th√™m chi·ªÅu Batch (Batch Dimension)
                    # T·ª´ (3, 224, 224) -> (1, 3, 224, 224)
                    img_tensor = img_tensor.unsqueeze(0) 
                    device = next(model.parameters()).device
                    img_tensor = img_tensor.to(device)
                    # 3. ƒê∆∞a v√†o Model
                    with torch.no_grad():
                        # N·∫øu deploy tr√™n CPU th√¨ kh√¥ng c·∫ßn .to(device) n·∫øu model ƒëang ·ªü CPU
                        outputs = model(img_tensor)
                        _, predicted = torch.max(outputs, 1)
                        confidence = torch.nn.functional.softmax(outputs, dim=1)[0] * 100
                    
                    # 4. Hi·ªÉn th·ªã k·∫øt qu·∫£
                    pred_label = classes[predicted.item()]
                    conf_score = confidence[predicted.item()].item()
                    
                    st.success(f"K·∫øt qu·∫£: **{pred_label}**")
                    st.info(f"ƒê·ªô tin c·∫≠y: {conf_score:.2f}%")
                    
                    # Bi·ªÉu ƒë·ªì
                    st.bar_chart({classes[i]: confidence[i].item() for i in range(len(classes))})
                    
                except Exception as e:
                    st.error(f"ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω ·∫£nh: {e}")